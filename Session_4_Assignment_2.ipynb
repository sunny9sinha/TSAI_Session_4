{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session_4_Assignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunny9sinha/TSAI_Session_4/blob/main/Session_4_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc338c65-7b7d-4bd2-9700-ec7d1f88640d"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "# import math\n",
        "def sigmoid(x): # sigmoid function\n",
        "  sig = 1/(1+np.exp(-x))\n",
        "  return sig # write your code here\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  dsig = y*(1-y)\n",
        "  return dsig # write your code here\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  tn = (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
        "  return tn # write your code here\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return (1-(y*y)) # write your code here"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzBQ39hhOAzT",
        "outputId": "6652931b-73bf-45e5-e1c9-0cb6aad9051a"
      },
      "source": [
        "sigmoid(0)"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJYt_q-1PJCZ",
        "outputId": "7d6457c1-07a8-43e5-81d8-4f0be3802fc2"
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7sUjWO5QSIM",
        "outputId": "bf7d78fd-224b-4792-94b2-641d5171d253"
      },
      "source": [
        "tanh(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24491866240370908"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC8kY8TpRjwT",
        "outputId": "4fc7d71e-3b52-4ed8-c25a-3a85106105ae"
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.940014848806378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size # write your code here\n",
        "size_b = z_size # write your code here\n",
        "size_c = X_size # write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11joLU_92yt1",
        "outputId": "69127dc5-7259-4a5d-ea8f-4816e41b97d7"
      },
      "source": [
        "z = np.row_stack((np.zeros((Hidden_Layer_size, 1)), np.zeros((X_size, 1))))\n",
        "z.shape"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(175, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "\n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v,z)+p.b_f.v) # write your code here\n",
        "    i = sigmoid(np.dot(p.W_i.v,z)+p.b_i.v)# write your code here\n",
        "    C_bar = tanh(np.dot(p.W_C.v,z)+p.b_C.v)# write your code here\n",
        "    C = f*C_prev+i*C_bar # write your code here\n",
        "    o = sigmoid(np.dot(p.W_o.v,z)+p.b_o.v) # write your code here\n",
        "    h = o*tanh(C) # write your code here\n",
        "\n",
        "    v = np.dot(p.W_v.v,h)+p.b_v.v # write your code here\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "   \n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuuWhMgTxgVl",
        "outputId": "b64ed3c7-750e-4497-f7d8-ebf4b11386dc"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27CQRs4dk1Ej",
        "outputId": "2d92d1b9-a246-4127-907e-33d80065cb39"
      },
      "source": [
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n",
            "0.0\n",
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "727e6d0e-f4ec-44a4-8f9e-dd1c264f16d8"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " go seve animal tare ovecyon, which weall everte a vey dow cants to find ortatemblo officia s renother include China, and not suad from Saud the sour madd patientsy iftat ont care therece cond forethon \n",
            "----\n",
            "iter 49900, loss 5.787372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    }
  ]
}